{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib3.exceptions import ConnectTimeoutError,MaxRetryError,SSLError,ConnectionError,ProtocolError\n",
    "from ssl import SSLCertVerificationError\n",
    "\n",
    "def scrape_p(url):\n",
    "  try:\n",
    "    response = requests.get(url)\n",
    "  except (ConnectTimeoutError,MaxRetryError, requests.exceptions.SSLError,requests.exceptions.ConnectionError,ProtocolError):\n",
    "    return ''\n",
    "  soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "  paragraphs = soup.find_all(\"p\")\n",
    "  scraped_doc = []\n",
    "  for p in paragraphs:\n",
    "    scraped_doc.append(p.get_text())\n",
    "\n",
    "  return ' '.join(scraped_doc).replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_collection = chroma_client.create_collection(name=\"machine_learning\")\n",
    "dl_collection = chroma_client.create_collection(name=\"deep_learning\")\n",
    "nlp_collection = chroma_client.create_collection(name=\"natural_language_processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# ml_topics_set = list(pd.read_csv('dbpedia_machinelearning.csv')['nodeLabel'])\n",
    "# dl_topics_set = list(pd.read_csv('dbpedia_deeplearning.csv')['nodeLabel'])\n",
    "# nlp_topics_set = list(pd.read_csv('dbpedia_NLP.csv')['nodeLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki_docs_collection(topics_set):\n",
    "  docs = []\n",
    "  wiki_url = \"https://en.wikipedia.org/wiki/\"\n",
    "  for topic in topics_set:\n",
    "    doc = scrape_p(wiki_url + str(topic).replace(' ','_'))\n",
    "    docs.append(doc)\n",
    "  return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def store_wiki_docs_collection(topics_set,folder_name):\n",
    "  Path(folder_name).mkdir(parents=True, exist_ok=True)\n",
    "  wiki_url = \"https://en.wikipedia.org/wiki/\"\n",
    "  for topic in topics_set:\n",
    "    doc = scrape_p(wiki_url + str(topic).replace(' ','_'))\n",
    "    if '/' in str(topic):\n",
    "      topic = str(topic).replace('/','_')\n",
    "    with open(folder_name+'/'+str(topic)+'.txt',\"w\",encoding=\"utf-8\") as file:\n",
    "      file.write(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store_wiki_docs_collection(ml_topics_set,'ml_wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store_wiki_docs_collection(dl_topics_set,'dl_wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store_wiki_docs_collection(nlp_topics_set,'nlp_wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_topics_set = ['Machine learning','Deep learning','Natural language processing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store_wiki_docs_collection(base_topics_set,'base_wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_reference_nums(text):\n",
    "    return re.sub(r\"\\[\\d+\\]\",'',text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ml_dir = r'raw/ml_wiki'\n",
    "\n",
    "def load_collection(collection,docs_directory):\n",
    "    raw_docs = []\n",
    "    for (root, dirs, file) in os.walk(docs_directory):\n",
    "        raw_docs = file\n",
    "\n",
    "    for raw_doc in raw_docs:\n",
    "        id = ''\n",
    "        doc = ''\n",
    "        with open('/'.join([docs_directory,raw_doc]),\"r\",encoding=\"utf-8\") as file:\n",
    "            id = raw_doc.removesuffix('.txt').replace('_','/')\n",
    "            doc = remove_reference_nums(file.readline())\n",
    "        collection.add(documents=[doc],ids=[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_article = ''\n",
    "with open('raw/base_wiki/Machine learning.txt',\"r\",encoding=\"utf-8\") as file:\n",
    "    ml_article = remove_reference_nums(file.readline())\n",
    "\n",
    "dl_article = ''\n",
    "with open('raw/base_wiki/Deep learning.txt',\"r\",encoding=\"utf-8\") as file:\n",
    "    dl_article = remove_reference_nums(file.readline())\n",
    "\n",
    "nlp_article = ''\n",
    "with open('raw/base_wiki/Natural language processing.txt',\"r\",encoding=\"utf-8\") as file:\n",
    "    nlp_article = remove_reference_nums(file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_dir = r'raw/ml_wiki'\n",
    "dl_dir = r'raw/dl_wiki'\n",
    "nlp_dir = r'raw/nlp_wiki'\n",
    "\n",
    "# load_collection(ml_collection,ml_dir)\n",
    "# load_collection(dl_collection,dl_dir)\n",
    "# load_collection(nlp_collection,nlp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_relevant_topics(collection,query_article,num,file_name):\n",
    "    results = collection.query(\n",
    "        query_texts = [query_article],\n",
    "        n_results = num\n",
    "    )\n",
    "    with open(file_name+'.txt',\"w\",encoding=\"utf-8\") as file:\n",
    "        file.write('\\n'.join(results['ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_nums = [5,10,15,25,50,100,250,500,750,1000,1250,1500,1750,2000,2500]\n",
    "\n",
    "# for num in topic_nums:\n",
    "#     store_relevant_topics(ml_collection,ml_article,num,'topics/ml/ml_'+str(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_nums = [5,10,15,25,50,100,250,500,750,1000,1250,1500,1750,2000,2500]\n",
    "\n",
    "# for num in topic_nums:\n",
    "#     store_relevant_topics(dl_collection,dl_article,num,'topics/dl/dl_'+str(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_nums = [5,10,15,25,50,100,250,500,750,1000,1250,1500,1750,2000,2500]\n",
    "\n",
    "# for num in topic_nums:\n",
    "#     store_relevant_topics(nlp_collection,nlp_article,num,'topics/nlp/nlp_'+str(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import json\n",
    "\n",
    "def get_article_links(topics_file_path,output_file_path,number_of_articles):\n",
    "    topics = []\n",
    "    with open(topics_file_path,\"r\",encoding=\"utf-8\") as file:\n",
    "        topics = file.readlines()\n",
    "    topics = [s.replace('\\n','') for s in topics]\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    linkdict = dict()\n",
    "    for query in topics:\n",
    "        url = f'https://www.startpage.com/search?q={query}'\n",
    "        driver.get(url)\n",
    "        filter = ['wikipedia','youtube']\n",
    "        links = []\n",
    "        for link in driver.find_elements(By.CLASS_NAME,'result-link'):\n",
    "            if any(substring in link.get_attribute('href') for substring in filter):\n",
    "                continue\n",
    "            links.append(link.get_attribute('href'))\n",
    "        linkdict[query] = links[:number_of_articles]\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    with open(output_file_path+'/'+query+'.json','w',encoding='utf-8') as file:\n",
    "        file.write(json.dumps(linkdict,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_topics_file = r'topics/ml/ml_2500.txt'\n",
    "dl_topics_file = r'topics/dl/dl_2500.txt'\n",
    "nlp_topics_file = r'topics/nlp/nlp_2500.txt'\n",
    "\n",
    "# get_article_links(ml_topics_file,'aug3/ml',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "\n",
    "def get_article_links_gibiru(topics_file_path,output_file_path,number_of_articles):\n",
    "    topics = []\n",
    "    with open(topics_file_path,\"r\",encoding=\"utf-8\") as file:\n",
    "        topics = file.readlines()\n",
    "    topics = [s.replace('\\n','') for s in topics]\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    for query in topics:\n",
    "        url = f'https://www.gibiru.com/results.html?q={query}'\n",
    "        time.sleep(random.randint(10,15))\n",
    "        driver.get(url)\n",
    "        filter = ['wikipedia','youtube']\n",
    "        links = []\n",
    "        for link in driver.find_elements(By.CSS_SELECTOR,'a.gs-title'):\n",
    "            if link.get_attribute('data-ctorig'):\n",
    "                if any(substring in link.get_attribute('data-ctorig') for substring in filter):\n",
    "                    continue\n",
    "            if link.get_attribute('data-ctorig') not in links:\n",
    "                links.append(link.get_attribute('data-ctorig'))\n",
    "        \n",
    "        mod_query = query.replace('/','_')\n",
    "        with open(output_file_path+'/'+mod_query+'.json','w',encoding='utf-8') as file:\n",
    "            file.write(json.dumps(links[:number_of_articles],indent=4))\n",
    "        print(mod_query,':',len(links)>0)\n",
    "    driver.quit()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_article_links_gibiru('topics/dl/dl_5.txt','topics',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_topics_file = r'topics/ml/ml_2500.txt'\n",
    "dl_topics_file = r'topics/dl/dl_2500.txt'\n",
    "nlp_topics_file = r'topics/nlp/nlp_2500.txt'\n",
    "\n",
    "# get_article_links_gibiru(ml_topics_file,'aug5/ml',5)\n",
    "# get_article_links_gibiru(dl_topics_file,'aug5/dl',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_report2 = \"\"\"\n",
    "Convolutional neural network : True\n",
    "Artificial neural networks : True\n",
    "Contrastive divergence : True\n",
    "Restricted Boltzmann machine : True\n",
    "Kunihiko Fukushima : True\n",
    "Text-to-image generation : True\n",
    "Neuromorphic computing : False\n",
    "Training set : True\n",
    "Image classification : True\n",
    "Comparison of deep learning software : True\n",
    "Comparison of deep-learning software : True\n",
    "Artificial intelligence : True\n",
    "LSTM : True\n",
    "Echo state network : False\n",
    "CLARION (cognitive architecture) : True\n",
    "WaveNet : True\n",
    "Cognitive modelling : True\n",
    "Connectomics : True\n",
    "Group method of data handling : True\n",
    "Russ Salakhutdinov : True\n",
    "Medical algorithm : True\n",
    "Alex Krizhevsky : True\n",
    "Computer science : True\n",
    "Computer sciences : True\n",
    "ImageNet competition : True\n",
    "ImageNet Large Scale Visual Recognition Challenge : True\n",
    "ImageNet : True\n",
    "Network architecture : True\n",
    "Adaptive resonance theory : True\n",
    "Boltzmann machine : True\n",
    "LIDA (cognitive architecture) : True\n",
    "Christopher Bishop : True\n",
    "Memory : True\n",
    "Synapse : True\n",
    "Word-sense disambiguation : True\n",
    "Decision tree learning : True\n",
    "Gini impurity : True\n",
    "Max Planck Institute for Biological Cybernetics : True\n",
    "Biological cybernetics : True\n",
    "Multiclass classification : True\n",
    "CPU : True\n",
    "Mental exercise : True\n",
    "Computer network : True\n",
    "Relationship extraction : True\n",
    "Computer memory : True\n",
    "Novelty detection : True\n",
    "Generative model : True\n",
    "Receptive field : True\n",
    "Linear classifier : True\n",
    "Natural language : True\n",
    "Short-term memory : True\n",
    "Face Recognition Grand Challenge : True\n",
    "Field-programmable gate array : True\n",
    "Cyborgs : True\n",
    "OpenAI Five : True\n",
    "Photo restoration : True\n",
    "Support vector machine : True\n",
    "Support-vector machine : True\n",
    "Seq2seq : True\n",
    "Computer engineering : True\n",
    "Backpropagation through time : True\n",
    "Digital circuit : True\n",
    "Aging brain : True\n",
    "Offline learning : True\n",
    "Rprop : True\n",
    "Mathematical structures : True\n",
    "Binary classification : True\n",
    "Primary auditory cortex : True\n",
    "Image registration : True\n",
    "Description logic : True\n",
    "Brain development : True\n",
    "FERET (facial recognition technology) : True\n",
    "BCM theory : True\n",
    "Edge detection : True\n",
    "Parallel distributed processing : True\n",
    "Speeded up robust features : True\n",
    "Quantum computing : True\n",
    "Optimization : True\n",
    "Decision list : True\n",
    "Multi-agent reinforcement learning : True\n",
    "Hardware accelerator : True\n",
    "Algorithms : True\n",
    "NaÃ¯ve algorithm : True\n",
    "Terry Sejnowski : True\n",
    "Microwork : True\n",
    "Myelin sheath : True\n",
    "Scale space : True\n",
    "Health Level 7 : True\n",
    "Image restoration : True\n",
    "Dual space : True\n",
    "Differentiable programming : True\n",
    "ICD-11 : True\n",
    "Web Ontology Language : False\n",
    "Stochastic context-free grammar : True\n",
    "Scale-invariant feature transform : True\n",
    "Backdoor (computing) : True\n",
    "Andrew Ng : True\n",
    "Neurotrophic factor : True\n",
    "Semantic web : True\n",
    "Computational complexity theory : True\n",
    "Floating-gate : True\n",
    "Neural backpropagation : True\n",
    "Language : True\n",
    "Attention : True\n",
    "ID3 algorithm : True\n",
    "Scale-space segmentation : True\n",
    "AI-complete : True\n",
    "Automated reasoning : True\n",
    "Ridge detection : True\n",
    "Medications : True\n",
    "Field extension : True\n",
    "Limbic : True\n",
    "Inferential programming : True\n",
    "Generalization : True\n",
    "Automation : True\n",
    "Ben Goertzel : True\n",
    "Text mining : True\n",
    "Algorithmic paradigm : True\n",
    "Neurodevelopmental disorder : True\n",
    "Nonlinear system identification : True\n",
    "Difference of Gaussians : True\n",
    "Function of several real variables : True\n",
    "Visual cortex : True\n",
    "Algorithmic bias : True\n",
    "Knowledge extraction : True\n",
    "Service delivery platform : True\n",
    "Overfitting : True\n",
    "Cellular network : True\n",
    "Gene Ontology : True\n",
    "Conductive trace : True\n",
    "Printed circuit board : True\n",
    "Douglas Lenat : True\n",
    "Intelligent personal assistant : True\n",
    "Digital data : True\n",
    "Cognition : True\n",
    "Cognitive : True\n",
    "Divide-and-conquer algorithm : True\n",
    "Category (mathematics) : True\n",
    "MIT Computer Science and Artificial Intelligence Laboratory : True\n",
    "Guillermo Sapiro : True\n",
    "Symbolic artificial intelligence : True\n",
    "Mipmap : True\n",
    "Overhead Imagery Research Data Set : True\n",
    "Semiconductor : True\n",
    "Semiconductors : True\n",
    "Smoothing : True\n",
    "Electroencephalography : True\n",
    "Database : True\n",
    "Simulated annealing : True\n",
    "Analog-to-digital converter : True\n",
    "Statistical machine translation : True\n",
    "Cybernetics : True\n",
    "Evolutionary algorithm : True\n",
    "Semantic role labeling : True\n",
    "Information and communications technology : True\n",
    "Big data : True\n",
    "Quantum algorithm : True\n",
    "Digital communications : True\n",
    "Vector space : True\n",
    "Vector spaces : True\n",
    "Mycin : True\n",
    "Inverse problems : True\n",
    "Question answering : True\n",
    "Multiscale mathematics : True\n",
    "Cognitive reserve : True\n",
    "Binary Space Partition : True\n",
    "Richard Mattson : True\n",
    "Finite-state machine : True\n",
    "Propositional logic : True\n",
    "Texture synthesis : True\n",
    "Knowledge base : True\n",
    "Quick, Draw! : True\n",
    "Confusion matrix : True\n",
    "John E. Laird : True\n",
    "Natural-language user interface : True\n",
    "Conservation and restoration of photographs : False\n",
    "Partial function : True\n",
    "Formal grammar : True\n",
    "Electronic component : False\n",
    "Xeon : True\n",
    "Deterministic algorithm : True\n",
    "Homeland security : True\n",
    "Boltzmann distribution : True\n",
    "Natural language parsing : True\n",
    "Recursion : True\n",
    "Eigenstate : True\n",
    "Recursion (computer science) : True\n",
    "Recursive algorithm : True\n",
    "Computer optimization : True\n",
    "Bayesian inference in motor learning : True\n",
    "Microsoft Research : True\n",
    "American Association of Artificial Intelligence : True\n",
    "Autonomous driving : True\n",
    "Text simplification : True\n",
    "Biomolecular target : True\n",
    "Freebase (database) : True\n",
    "Genome biology : True\n",
    "Physician : True\n",
    "Drug candidate : True\n",
    "Edward W. Veitch : True\n",
    "3Blue1Brown : True\n",
    "Software patent : True\n",
    "Heuristic : True\n",
    "Truecasing : True\n",
    "Shenlan SL03 : True\n",
    "Covector : True\n",
    "Wireless gateway : True\n",
    "Probability theory : True\n",
    "Search algorithm : True\n",
    "TD-Gammon : True\n",
    "Information system : True\n",
    "Infrared cleaning : False\n",
    "Solomonoff's theory of inductive inference : True\n",
    "Single instruction, multiple threads : True\n",
    "Macrophage : True\n",
    "Institute for Computational Engineering and Sciences : True\n",
    "Moore's law : True\n",
    "Landline : True\n",
    "Bayesian hierarchical modeling : True\n",
    "Hebbian learning : True\n",
    "CRM114 (program) : True\n",
    "Face detection : True\n",
    "Arithmetic : True\n",
    "Resistor : True\n",
    "Evolutionary programming : True\n",
    "Monocyte : True\n",
    "Set-top box : True\n",
    "Lewy body disease : True\n",
    "Wavefunction : True\n",
    "Donald Knuth : True\n",
    "SHRDLU : False\n",
    "Proposition (logic) : True\n",
    "Propositions : True\n",
    "Marcus Hutter : False\n",
    "Propositional function : False\n",
    "National Science Foundation : False\n",
    "Optimization problem : False\n",
    "Combinatorial : False\n",
    "String algorithms : False\n",
    "Neuroplastic effects of pollution : False\n",
    "TinEye : False\n",
    "Image reconstruction : False\n",
    "Computer hardware : False\n",
    "Lebesgue integral : False\n",
    "Lebesgue integration : False\n",
    "Subjective logic : True\n",
    "Nonmonotonic logic : True\n",
    "Named entity : True\n",
    "Contour line : True\n",
    "CONTSYS : True\n",
    "Force : True\n",
    "Computational geometry : True\n",
    "Physics : True\n",
    "Regression analysis : True\n",
    "Analog circuit : True\n",
    "Analog electronics : False\n",
    "Cleverbot : True\n",
    "Tara Spires-Jones : True\n",
    "Electrical engineering : True\n",
    "Seam carving : True\n",
    "Introduction to Algorithms : True\n",
    "Data modeling : True\n",
    "Tokenization (lexical analysis) : False\n",
    "Cognitive psychology : True\n",
    "Latent variable : False\n",
    "Latent variables : True\n",
    "Cyc : True\n",
    "Frame semantics (linguistics) : True\n",
    "Libratus : True\n",
    "Alzheimer's disease : True\n",
    "Linear programming : True\n",
    "Huffman coding : True\n",
    "Amazon Mechanical Turk : True\n",
    "Customer value maximization : True\n",
    "Li Zhaoping : True\n",
    "Technological change : True\n",
    "Conceptual metaphor : True\n",
    "Chart parsing : True\n",
    "animal : False\n",
    "Donald Hebb : True\n",
    "Signal processing : False\n",
    "Mathematical statistics : True\n",
    "Backus-Naur form : True\n",
    "Psychosis : True\n",
    "Conservator-restorer : True\n",
    "WordNet : True\n",
    "Federal Bureau of Investigation : True\n",
    "System integration : True\n",
    "Engineering : True\n",
    "Cookbook : True\n",
    "Markov chain Monte Carlo : True\n",
    "Parietal lobe : True\n",
    "Time series prediction : True\n",
    "Time series : True\n",
    "Universal (metaphysics) : True\n",
    "Medicine : False\n",
    "Executive functions : True\n",
    "Reason : False\n",
    "Reasoning : True\n",
    "Transducer : True\n",
    "Michael Collins (computational linguist) : True\n",
    "Board game : True\n",
    "Acetylcholine : True\n",
    "Semiotics : True\n",
    "protein : True\n",
    "Proteins : True\n",
    "Algorithmic topology : True\n",
    "Compound term processing : True\n",
    "Stack (data structure) : True\n",
    "Backward chaining : True\n",
    "Differential manifold : True\n",
    "Execution (computing) : False\n",
    "Clinical and Translational Science Award : True\n",
    "Affine deformation : True\n",
    "Sobolev space : True\n",
    "Coarticulation : True\n",
    "Propositional formula : True\n",
    "State diagram : True\n",
    "General Atomics MQ-9 Reaper : True\n",
    "Symbolic language (programming) : True\n",
    "Closed-form expression : True\n",
    "Nursing home : True\n",
    "FORR : True\n",
    "National Academy of Engineering : True\n",
    "Flowchart : True\n",
    "Distributed computing : True\n",
    "National Electrical Manufacturers Association : True\n",
    "Data center : True\n",
    "Hyperparameter : True\n",
    "Massage : False\n",
    "Monte Carlo method : True\n",
    "Monte Carlo methods : True\n",
    "Affine shape adaptation : True\n",
    "Algorithmic synthesis : True\n",
    "John Brennan (CIA officer) : True\n",
    "NMDA receptor : True\n",
    "Diode : True\n",
    "Dimension : True\n",
    "Transduction (machine learning) : True\n",
    "Emergent behavior : True\n",
    "Karnaugh map : True\n",
    "Veitch diagram : True\n",
    "Numerical analysis : True\n",
    "Dementia with Lewy bodies : True\n",
    "Algorithm analysis : True\n",
    "Analysis of algorithms : True\n",
    "Static random-access memory : True\n",
    "Government by algorithm : False\n",
    "Theano (software) : True\n",
    "Relay : True\n",
    "Function spaces : True\n",
    "Inner product : True\n",
    "Masking (Electronic Health Record) : False\n",
    "Home care : True\n",
    "Kleene : True\n",
    "Non-deterministic algorithm : True\n",
    "Dialect : True\n",
    "ASC X12 : True\n",
    "Inferior colliculus : True\n",
    "Biomarkers of aging : True\n",
    "Aerobic exercise : True\n",
    "Text corpus : True\n",
    "Impredicative definition : True\n",
    "Base station subsystem : True\n",
    "Computational mathematics : True\n",
    "Amyloid plaques : True\n",
    "Breadboard : True\n",
    "Principal Component Analysis : True\n",
    "Security alarm : True\n",
    "Argument : True\n",
    "Rule of inference : True\n",
    "Huawei Mate 20 : True\n",
    "BT 21CN : True\n",
    "Blind signal separation : True\n",
    "Health care : True\n",
    "Bayesian search theory : True\n",
    "AIXI : True\n",
    "Realtek : True\n",
    "Deductive reasoning : True\n",
    "Wikidata : True\n",
    "RFM (customer value) : True\n",
    "Acrylic paint : False\n",
    "Validity (logic) : False\n",
    "Wireless : True\n",
    "ArchNet : True\n",
    "Real coordinate space : True\n",
    "Binary function : True\n",
    "Corner detection : True\n",
    "Bayesian probability : True\n",
    "Deductivism : True\n",
    "Hypothetico-deductive method : True\n",
    "Hypothetico-deductive model : True\n",
    "Probabilistic logic : True\n",
    "White House Chief of Staff : True\n",
    "Computer and network surveillance : True\n",
    "NIH : True\n",
    "Validation therapy : True\n",
    "Histopathology : True\n",
    "Robustness (computer science) : True\n",
    "Decision support system : True\n",
    "Gliosis : True\n",
    "United States Secretary of State : True\n",
    "Matrix notation : True\n",
    "Automatic translation : True\n",
    "Conservation and restoration of cultural heritage : True\n",
    "Corticobasal degeneration : True\n",
    "Entropy maximization : True\n",
    "Dietrich DÃ¶rner : True\n",
    "Tag (Facebook) : True\n",
    "Emmanuel Macron : True\n",
    "Massachusetts Institute of Technology : True\n",
    "MIT : True\n",
    "Method of analytic tableaux : True\n",
    "Module (mathematics) : True\n",
    "Petal Search : True\n",
    "Data privacy : True\n",
    "Royal Military Academy (Belgium) : True\n",
    "Lambda calculus : True\n",
    "Presidency of Joe Biden : True\n",
    "Peptide hormones : True\n",
    "Ian Hacking : True\n",
    "Formulas : True\n",
    "Activity tracker : True\n",
    "European Union : True\n",
    "John Robert Anderson (psychologist) : True\n",
    "Apoptosis : True\n",
    "Association for Computing Machinery : True\n",
    "Surjective : True\n",
    "Entrepreneurship : True\n",
    "Conjunctive normal form : True\n",
    "television station : True\n",
    "National Intelligence Law of the People's Republic of China : True\n",
    "Iteration : False\n",
    "P-vector : True\n",
    "Posterior distribution : True\n",
    "Endomorphism ring : True\n",
    "Baidu : True\n",
    "Metric space : True\n",
    "Differentiable function : True\n",
    "Marginal likelihood : True\n",
    "John Venn : True\n",
    "Overlapping subproblems : True\n",
    "Square matrix : True\n",
    "Eli Wallach : True\n",
    "U.S. Army Research Laboratory : True\n",
    "Sophia Antipolis : True\n",
    "Parkinsonism : True\n",
    "Denying a conjunct : True\n",
    "HongMeng OS : True\n",
    "Logical reasoning : True\n",
    "CREB : True\n",
    "Tangent space : True\n",
    "Software patent debate : True\n",
    "Decision theory : True\n",
    "Minterms : True\n",
    "Carnegie Classification of Institutions of Higher Education : True\n",
    "Statistical : True\n",
    "European Commission : True\n",
    "Laplacian : True\n",
    "Unsaturated fatty acid : True\n",
    "False positives and false negatives : True\n",
    "Multiplyâ€“accumulate operation : True\n",
    "Section (fiber bundle) : True\n",
    "Cognitive behavioral therapy : True\n",
    "Scale (ratio) : True\n",
    "Ontology (information science) : True\n",
    "Potentiometer : True\n",
    "Prim's algorithm : True\n",
    "Dirichlet boundary condition : True\n",
    "Factor Graphs : True\n",
    "Coreference : True\n",
    "Fault tree analysis : True\n",
    "Integral : True\n",
    "Orientation (vector space) : True\n",
    "Toxicity : True\n",
    "Passive optical network : False\n",
    "HiSilicon : True\n",
    "High blood pressure : True\n",
    "Hypertension : True\n",
    "Cerebral atherosclerosis : True\n",
    "Formula (mathematical logic) : True\n",
    "Well formed formula : True\n",
    "Well-formed formula : True\n",
    "Air pollution : True\n",
    "Cannabinoid : True\n",
    "Export Administration Regulations : True\n",
    "Management science : True\n",
    "William H. McRaven : True\n",
    "Complex numbers : True\n",
    "Closure (mathematics) : True\n",
    "Malware : False\n",
    "Contribution margin : False\n",
    "Solder : False\n",
    "Faroe Islands : False\n",
    "Freshman Research Initiative : False\n",
    "Logical quantifier : False\n",
    "U.S. Senate : False\n",
    "Local extrema : False\n",
    "Local optimum : False\n",
    "Minima : False\n",
    "Recipe : False\n",
    "University of California, Irvine : False\n",
    "Point (geometry) : False\n",
    "Emil Kraepelin : False\n",
    "Xbox : False\n",
    "Cash flows : False\n",
    "Multiple sclerosis : False\n",
    "Coordinates : False\n",
    "Diffusion equation : False\n",
    "Approximation algorithm : False\n",
    "Digital video : False\n",
    "Bernhard Bolzano : False\n",
    "Locally : False\n",
    "Implicit function theorem : False\n",
    "HIV_AIDS : False\n",
    "Orthogonal basis : False\n",
    "Ordered pair : False\n",
    "Integer programming : False\n",
    "Chinese language : False\n",
    "Relevance : False\n",
    "Neta S : False\n",
    "Universal property : False\n",
    "Structured program theorem : False\n",
    "Halite AI Programming Competition : False\n",
    "Stock market prediction : False\n",
    "Vital signs : False\n",
    "PI3K_AKT_mTOR pathway : False\n",
    "Binomial distribution : False\n",
    "Row and column vectors : False\n",
    "Commutative law : False\n",
    "Commutative : False\n",
    "Commutativity : False\n",
    "NCAA Division I FBS : False\n",
    "Constraint programming : False\n",
    "Axiom system : False\n",
    "Postdoctoral research : False\n",
    "Memantine : False\n",
    "Allen Newell : False\n",
    "Mean : False\n",
    "Cognitive linguistics : False\n",
    "Babylonian astronomy : False\n",
    "Olive oil : False\n",
    "Beta cells : False\n",
    "Electricity : False\n",
    "Paul C. Rosenbloom : False\n",
    "Belief : False\n",
    "Comma-separated values : False\n",
    "Sentence breaking : False\n",
    "ISO TC 215 : False\n",
    "Calcium in biology : False\n",
    "Gothic Revival architecture : False\n",
    "Radiotracer : False\n",
    "Google Fuchsia : False\n",
    "Clock : False\n",
    "Timelike : False\n",
    "Turkish language : False\n",
    "American English : False\n",
    "A. K. Dewdney : False\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('aug5/dl_report2.csv','w',encoding='utf-8') as file:\n",
    "#     file.write(dl_report2.replace(':',','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fileinput\n",
    "# import sys\n",
    "\n",
    "# for line in fileinput.input('aug5/dl_report2.csv', inplace=True):\n",
    "#     sys.stdout.write('\"{l}'.format(l=line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "\n",
    "def get_missing_article_links_gibiru(missing_topics_list,output_file_path,number_of_articles):\n",
    "    topics = missing_topics_list\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    for query in topics:\n",
    "        url = f'https://www.gibiru.com/results.html?q={query}'\n",
    "        time.sleep(random.randint(10,15))\n",
    "        driver.get(url)\n",
    "        filter = ['wikipedia','youtube']\n",
    "        links = []\n",
    "        for link in driver.find_elements(By.CSS_SELECTOR,'a.gs-title'):\n",
    "            if link.get_attribute('data-ctorig'):\n",
    "                if any(substring in link.get_attribute('data-ctorig') for substring in filter):\n",
    "                    continue\n",
    "            if link.get_attribute('data-ctorig') not in links:\n",
    "                links.append(link.get_attribute('data-ctorig'))\n",
    "        \n",
    "        mod_query = query.replace('/','_')\n",
    "        with open(output_file_path+'/'+mod_query+'.json','w',encoding='utf-8') as file:\n",
    "            file.write(json.dumps(links[:number_of_articles],indent=4))\n",
    "        print(mod_query,':',len(links)>0)\n",
    "    driver.quit()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuromorphic computing : True\n",
      "Echo state network : False\n",
      "Web Ontology Language : False\n",
      "Conservation and restoration of photographs : True\n",
      "Electronic component : True\n",
      "Infrared cleaning : True\n",
      "SHRDLU : True\n",
      "Marcus Hutter : True\n",
      "Propositional function : True\n",
      "National Science Foundation : True\n",
      "Optimization problem : True\n",
      "Combinatorial : True\n",
      "String algorithms : True\n",
      "Neuroplastic effects of pollution : True\n",
      "TinEye : True\n",
      "Image reconstruction : True\n",
      "Computer hardware : True\n",
      "Lebesgue integral : True\n",
      "Lebesgue integration : True\n",
      "Analog electronics : True\n",
      "Tokenization (lexical analysis) : True\n",
      "Latent variable : True\n",
      "animal : True\n",
      "Signal processing : True\n",
      "Medicine : True\n",
      "Reason : True\n",
      "Execution (computing) : True\n",
      "Massage : True\n",
      "Government by algorithm : True\n",
      "Masking (Electronic Health Record) : True\n",
      "Acrylic paint : True\n",
      "Validity (logic) : True\n",
      "Iteration : True\n",
      "Passive optical network : True\n",
      "Malware : True\n",
      "Contribution margin : True\n",
      "Solder : True\n",
      "Faroe Islands : True\n",
      "Freshman Research Initiative : True\n",
      "Logical quantifier : True\n",
      "U.S. Senate : True\n",
      "Local extrema : True\n",
      "Local optimum : True\n",
      "Minima : True\n",
      "Recipe : True\n",
      "University of California, Irvine : True\n",
      "Point (geometry) : True\n",
      "Emil Kraepelin : True\n",
      "Xbox : True\n",
      "Cash flows : True\n",
      "Multiple sclerosis : True\n",
      "Coordinates : True\n",
      "Diffusion equation : True\n",
      "Approximation algorithm : True\n",
      "Digital video : True\n",
      "Bernhard Bolzano : True\n",
      "Locally : False\n",
      "Implicit function theorem : True\n",
      "HIV_AIDS : True\n",
      "Orthogonal basis : True\n",
      "Ordered pair : True\n",
      "Integer programming : True\n",
      "Chinese language : True\n",
      "Relevance : True\n",
      "Neta S : True\n",
      "Universal property : True\n",
      "Structured program theorem : True\n",
      "Halite AI Programming Competition : True\n",
      "Stock market prediction : True\n",
      "Vital signs : True\n",
      "PI3K_AKT_mTOR pathway : True\n",
      "Binomial distribution : True\n",
      "Row and column vectors : True\n",
      "Commutative law : True\n",
      "Commutative : True\n",
      "Commutativity : True\n",
      "NCAA Division I FBS : True\n",
      "Constraint programming : True\n",
      "Axiom system : True\n",
      "Postdoctoral research : True\n",
      "Memantine : True\n",
      "Allen Newell : True\n",
      "Mean : True\n",
      "Cognitive linguistics : True\n",
      "Babylonian astronomy : False\n",
      "Olive oil : False\n",
      "Beta cells : False\n",
      "Electricity : False\n",
      "Paul C. Rosenbloom : False\n",
      "Belief : False\n",
      "Comma-separated values : False\n",
      "Sentence breaking : False\n",
      "ISO TC 215 : False\n",
      "Calcium in biology : False\n",
      "Gothic Revival architecture : False\n",
      "Radiotracer : False\n",
      "Google Fuchsia : False\n",
      "Clock : False\n",
      "Timelike : False\n",
      "Turkish language : False\n",
      "American English : False\n",
      "A. K. Dewdney : False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('aug5/dl_report2.csv')\n",
    "dl_missing1 = list(df1[df1['Successful']==False]['Topic'])\n",
    "\n",
    "get_missing_article_links_gibiru(dl_missing1,'aug5/dl',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('aug5/ml_report1.csv')\n",
    "ml_missing1 = list(df[df['Successful']==False]['Topic'])\n",
    "with open('topics/ml/ml_2500.txt','r') as file:\n",
    "    l = file.readlines()\n",
    "l = [s.replace('\\n','') for s in l]\n",
    "messed_up = []\n",
    "for missing in ml_missing1:\n",
    "    if missing not in l:\n",
    "        messed_up.append(missing)\n",
    "# print(messed_up)\n",
    "# print(l[1930])\n",
    "\n",
    "# get_missing_article_links_gibiru(ml_missing1,'aug5/ml',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('aug5/ml_report2.csv','w',encoding='utf-8') as file:\n",
    "#     file.write(ml_report2.replace(':',','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fileinput\n",
    "# import sys\n",
    "\n",
    "# for line in fileinput.input('aug5/ml_report2.csv', inplace=True):\n",
    "#     sys.stdout.write('\"{l}'.format(l=line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.read_csv('aug5/ml_report2.csv')\n",
    "ml_missing2 = list(df2[df2['Successful']==False]['Topic'])\n",
    "\n",
    "# get_missing_article_links_gibiru(ml_missing2,'aug5/ml',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('aug5/ml_report3.csv','w',encoding='utf-8') as file:\n",
    "#     file.write(ml_report3.replace(':',','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fileinput\n",
    "# import sys\n",
    "\n",
    "# for line in fileinput.input('aug5/ml_report3.csv', inplace=True):\n",
    "#     sys.stdout.write('\"{l}'.format(l=line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df3 = pd.read_csv('aug5/ml_report3.csv')\n",
    "ml_missing3 = list(df3[df3['Successful']==False]['Topic'])\n",
    "\n",
    "# get_missing_article_links_gibiru(ml_missing3,'aug5/ml',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def get_articles(docs_directory,output_directory):\n",
    "    raw_docs = []\n",
    "    for (root, dirs, file) in os.walk(docs_directory):\n",
    "        raw_docs = file\n",
    "    \n",
    "    for doc in raw_docs:\n",
    "        links = []\n",
    "        with open(docs_directory+'/'+doc,'r',encoding='utf-8') as file:\n",
    "            links = json.load(file)\n",
    "        \n",
    "        for i,link in enumerate(links):\n",
    "            article = scrape_p(link)\n",
    "            fname = doc.removesuffix('.json')+ ' '+str(i)\n",
    "            # article = f'[Topic:{doc.removesuffix('.json')}, Link:{link}]'+article\n",
    "            \n",
    "            with open(output_directory+'/'+fname+'.txt','w',encoding='utf-8') as file:\n",
    "                file.write(article)\n",
    "            if i < 4:\n",
    "                print(fname + ' saved ðŸ‘†')\n",
    "            else:\n",
    "                print(fname+' saved ðŸ‘Œ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_articles('aug5/ml','aug5_docs/ml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
